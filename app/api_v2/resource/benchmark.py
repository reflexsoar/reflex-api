from flask_restx import Resource, Namespace, fields, inputs as xinputs

from ..utils import token_required, user_has
from .shared import ISO8601, mod_user_list, NullableString

from app.api_v2.model import Q, Agent

from app.api_v2.model.benchmark import (
    BenchmarkRule, BenchmarkRuleset, BenchmarkResult, BENCHMARK_STATUSES,
    BenchmarkResultHistory
)

api = Namespace('Benchmark', description='Benchmark', path='/benchmark')

mod_benchmark_rule_assess = api.model('BenchmarkRuleAssess', {
    'language': fields.String(required=True, description='The language of the script'),
    'script': fields.String(required=True, description='The script to assess the rule'),
    'args': fields.List(fields.String(required=False, description='The arguments to pass to the script')),
    'success': fields.Integer(required=True, description='The expected success code from the script')
})

mod_benchmark_rule_details = api.model('BenchmarkRuleDetails', {
    'uuid': fields.String(description='The rule UUID'),
    'rule_id': fields.String(description='The rule ID'),
    'organization': fields.String(description='The organization UUID'),
    'name': fields.String(description='The rule name'),
    'description': fields.String(description='A description of why this rule exists and what it does'),
    'version': fields.Integer(description='The rule version'),
    'assess': fields.Nested(mod_benchmark_rule_assess, description='The script to assess the rule'),
    'remediation': fields.Nested(mod_benchmark_rule_assess, description='The script to remediate the rule'),
    'risk_score': fields.Integer(description='A risk score to set on alerts generated by this rule'),
    'severity': fields.Integer(description='The rule severity'),
    'auto_remediate': fields.Boolean(description='Should the rule be automatically remediated?'),
    'category': fields.List(fields.String(description='The rule category')),
    'frameworks': fields.List(fields.String(description='The rule framework')),
    'platform': fields.List(fields.String(description='The rule platform')),
    'created_at': ISO8601(description='The date and time the rule was created'),
    'updated_at': ISO8601(description='The date and time the rule was last updated'),
    'system_managed': fields.Boolean(description='Is the rule managed by the system?'),
    'created_by': fields.String(description='The user that created the rule'),
    'updated_by': fields.String(description='The user that last updated the rule')
})

mod_benchmark_rule_list = api.model('BenchmarkRuleList', {
    'rules': fields.List(fields.Nested(mod_benchmark_rule_details), description='The List of Rules')
})

mod_benchmark_ruleset_details = api.model('BenchmarkRulesetDetails', {
    'uuid': fields.String(description='The ruleset UUID'),
    'organization': fields.String(description='The organization UUID'),
    'name': fields.String(description='The ruleset name'),
    'rules': fields.List(fields.String(description='The rules in the ruleset')),
    'description': fields.String(description='A description of why this ruleset exists and what it does')
})

mod_benchmark_ruleset_list = api.model('BenchmarkRulesetList', {
    'rulesets': fields.List(fields.Nested(mod_benchmark_ruleset_details), description='The List of Rulesets')
})

mod_benchmark_metric = api.model('BenchmarkMetric', {
    'total': fields.Integer(description='The total number of results for the rule'),
    'passed': fields.Integer(description='The number of results that passed'),
    'failed': fields.Integer(description='The number of results that failed'),
    'error': fields.Integer(description='The number of results that had an error'),
    'skipped': fields.Integer(description='The number of results that were skipped')
})

mod_benchmark_result_metrics = api.model('BenchmarkResultMetrics', {
    'metrics': fields.List(fields.Nested(mod_benchmark_metric), description='The List of Metrics')
})

mod_benchmark_result_create = api.model('BenchmarkResultCreate', {
    'rule_id': fields.String(required=True, description='The rule ID'),
    'rule_uuid': fields.String(required=True, description='The rule UUID'),
    'status': fields.String(required=True, description='The result status'),
    'output': NullableString(required=False, description='The output of the check'),
    'assessed_at': ISO8601(required=True, description='The date and time the rule was assessed'),
    'rule_version': fields.Integer(required=True, description='The version of the rule')
})

mod_benchmark_result_create_bulk = api.model('BenchmarkResultCreateBulk', {
    'results': fields.List(fields.Nested(mod_benchmark_result_create), description='The List of Results')
})

metric_parser = api.parser()
metric_parser.add_argument('rule_uuids', type=str, action='split',
                           required=False,
                           help='The rule to filter on', location='args',
                           default=None)

@api.route("/metrics")
class BenchmarkRuleMetrics(Resource):

    @api.doc(security="Bearer")
    @api.expect(metric_parser)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('view_benchmarks')
    def get(self, current_user):
        '''List Benchmark Results'''

        args = metric_parser.parse_args()

        if args.rule_uuids is None:
            search = BenchmarkRule.search(skip_org_check=True)

            # Filter for organization is None or organization is the user's organization
            search = search.filter('bool', should=[Q('term', system_managed=True), Q('term', organization=current_user.organization)])

            # archived must not be true
            search = search.filter('bool', must_not=[Q('term', archived=True)])

            search = search.filter('term', current=True)

            results = search.scan()

            rule_uuids = [r.uuid for r in results]
        else:
            rule_uuids = args.rule_uuids

        rule_metrics = {}
        
        search = BenchmarkResult.search().filter('terms', rule_uuid=rule_uuids)

        for result in search.scan():
            if result.rule_id not in rule_metrics:
                rule_metrics[result.rule_id] = {
                    'total': 0,
                    'passed': 0,
                    'failed': 0,
                    'error': 0,
                    'skipped': 0
                }
            
            rule_metrics[result.rule_id]['total'] += 1
            rule_metrics[result.rule_id][result.status] += 1

        return {'metrics': rule_metrics}, 200


@api.route("/rules")
class BenchmarkRuleList(Resource):

    @api.doc(security="Bearer")
    @api.marshal_with(mod_benchmark_rule_list)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('view_benchmarks')
    def get(self, current_user):
        '''List Benchmark Rules'''
        search = BenchmarkRule.search(skip_org_check=True)

        # Filter for organization is None or organization is the user's organization
        search = search.filter('bool', should=[Q('term', system_managed=True), Q('term', organization=current_user.organization)])

        # Only return the current version of a rule
        search = search.filter('term', current=True)

        results = search.scan()

        return {'rules': list(results)}, 200
    

@api.route("/rules/<uuid>")
class BenchmarkRuleDetails(Resource):

    @api.doc(security="Bearer")
    @api.marshal_with(mod_benchmark_rule_details)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('view_benchmarks')
    def get(self, current_user, uuid):
        '''Get Benchmark Rule Details'''

        search = BenchmarkRule.search(skip_org_check=True)

        search = search.filter('bool', should=[Q('term', system_managed=True), Q('term', organization=current_user.organization)])

        result = search.filter('term', uuid=uuid).execute()

        if result:
            return result[0], 200
        else:
            return "Not Found", 404
    
mod_benchmark_asset = api.model('BenchmarkAsset', {
    'hostname': fields.String(required=True, description='The hostname of the asset'),
    'agent': fields.String(required=True, description='The agent UUID'),
    'status': fields.String(required=True, description='The result status'),
    'output': NullableString(required=False, description='The output of the check'),
    'assessed_at': ISO8601(required=True, description='The date and time the rule was assessed'),
    'rule_version': fields.Integer(required=True, description='The version of the rule')
})

mod_benchmark_asset_list = api.model('BenchmarkAssetList', {
    'assets': fields.Nested(mod_benchmark_asset)
})

@api.route("/rules/<uuid>/assets")
class BenchmarkRuleAssets(Resource):

    @api.doc(security="Bearer")
    @api.marshal_with(mod_benchmark_asset_list)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('view_benchmarks')
    def get(self, current_user, uuid):
        '''Gets the results for a specific rule on a per asset basis
        so that it can be displayed in the UI
        '''

        asset_results = []

        rule = BenchmarkRule.search()

        rule = rule.filter('bool', should=[Q('term', system_managed=True), Q('term', organization=current_user.organization)])

        rule = rule.filter('term', uuid=uuid).execute()

        # If there are no results, return an empty list
        if not rule:
            return {'assets': asset_results}, 200
        
        # If the rule is not system managed and the organization does not match
        # the user's organization, return an empty list
        if not rule[0].system_managed and rule[0].organization != current_user.organization:
            return {'assets': asset_results}, 200

        search = BenchmarkResult.search()

        search = search.filter('term', organization=current_user.organization)

        search = search.filter('term', rule_uuid=uuid)

        results = list(search.scan())
        
        agent_uuids = [r.agent for r in results]
        
        agents = Agent.search().filter('terms', uuid=agent_uuids).scan()

        agent_map = {a.uuid: a for a in agents}

        for result in results:
            try:
                agent = agent_map[result.agent]
                
                asset_results.append({
                    'hostname': agent.name if agent else 'Unknown',
                    'agent': result.agent,
                    'status': result.status,
                    'output': result.output,
                    'assessed_at': result.assessed_at,
                    'rule_version': result.rule_version
                })
            except KeyError:
                pass

        return {'assets': asset_results}, 200

mod_benchmark_rule_asset_history = api.model('BenchmarkRuleAssetHistory', {
    'history': fields.List(fields.Nested(mod_benchmark_result_create), description='The List of Results')
})

@api.route("/rules/<uuid>/assets/<asset_uuid>/history")
class BenchmarkRuleAssetHistory(Resource):

    @api.doc(security="Bearer")
    @api.marshal_with(mod_benchmark_rule_asset_history)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('view_benchmarks')
    def get(self, current_user, uuid, asset_uuid):
        '''Get Benchmark Rule Asset History'''

        search = BenchmarkResultHistory.search()

        search = search.filter('term', organization=current_user.organization)

        search = search.filter('term', rule_uuid=uuid)

        search = search.filter('term', agent=asset_uuid)

        results = search.scan()

        # Sort the results by created_at
        results = sorted(results, key=lambda x: x.created_at, reverse=True)

        return {'history': list(results)}, 200
    

def process_benchmark_result(data, current_user):
    '''
    Processes a benchmark result, can be called as a single
    result or as part of a bulk request
    '''
    # Check to see if there is already an existing result for this
    # rule, organization, agent, version and status
    search = BenchmarkResult.search()

    search = search.filter('term', rule_id=data['rule_id'])
    search = search.filter('term', agent=current_user.uuid)
    search = search.filter('term', rule_version=data['rule_version'])

    results = search.execute()

    # If there is an existing result, check to see if the status has changed
    # If the status has changed, create a new result and move the old result
    # to the history index
    if len(results) > 0:
        result = results[0]

        if result.status != data['status']:
            result.create_history_entry()

            result.status = data['status']
            result.output = data['output']
            result.assessed_at = data['assessed_at']
            result.save()

            return result
    else:
        # If there is no existing result, create a new one
        result = BenchmarkResult(**data, agent=current_user.uuid)
        result.save()
    return result

@api.route("/result/_bulk")
class BenchmarkResultCreateBulk(Resource):

    @api.doc(security="Bearer")
    @api.expect(mod_benchmark_result_create_bulk, validate=True)
    #@api.marshal_with(mod_benchmark_result_create)
    @api.response(201, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('create_benchmark_result')
    def post(self, current_user):
        '''Create Benchmark Result'''
        data = api.payload

        if 'results' in data and isinstance(data['results'], list):
            for result in data['results']:

                # Skip results that don't have a valid status
                if result['status'] not in BENCHMARK_STATUSES:
                    continue

                process_benchmark_result(result, current_user)

        return "Success", 201


@api.route("/result")
class BenchmarkResultCreate(Resource):

    @api.doc(security="Bearer")
    @api.expect(mod_benchmark_result_create, validate=True)
    @api.marshal_with(mod_benchmark_result_create)
    @api.response(200, 'Success')
    @api.response(401, 'Unauthorized')
    @token_required
    @user_has('create_benchmark_result')
    def post(self, current_user):
        '''Create Benchmark Result'''
        data = api.payload

        if data:

            if data['status'] not in BENCHMARK_STATUSES:
                return "Invalid status", 400
            
            result = process_benchmark_result(data, current_user)

        return result, 200